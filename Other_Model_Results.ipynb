{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from helpers import *\n",
    "from imp_functions import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x, ids = load_csv_data('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_call_log_reg(x,y,max_iters=1000,gamma=0.001):\n",
    "\n",
    "    x,_ = remove_outliers(x)\n",
    "    x, mean_x, std_x = normalize(x)\n",
    "    \n",
    "    x = build_model_data(x)\n",
    "    \n",
    "    y = convert_label(y,0)\n",
    "    initial_w = np.zeros((x.shape[1]))\n",
    "    \n",
    "    x_tr, x_val, y_tr, y_val = split_data(x, y, ratio = 0.8, myseed =7) #split the data for validation\n",
    "    \n",
    "    weight,_ = logistic_regression(y_tr, x_tr, initial_w, max_iters, gamma)\n",
    "\n",
    "    y_tr_pred = predict(x_tr,weight)\n",
    "\n",
    "    \n",
    "    y_val_pred = predict(x_val,weight)\n",
    "    \n",
    "    print('Training Accuracy : ', np.sum(y_tr_pred==convert_label(y_tr,-1))/y_tr.shape[0])\n",
    "    print('Validation Accuracy : ',np.sum(y_val_pred == convert_label(y_val,-1))/y_val.shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy :  0.711245\n",
      "Validation Accuracy :  0.70742\n"
     ]
    }
   ],
   "source": [
    "preprocess_and_call_log_reg(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_call_regularized_log_reg(x,y,max_iters=1000,gamma=0.001,lambda_=0.005):\n",
    "\n",
    "    x,_ = remove_outliers(x)\n",
    "\n",
    "    x, mean_x, std_x = normalize(x)\n",
    "    \n",
    "    x, _ = remove_high_correlation(x, threshold=0.9, visualisation=False)\n",
    "    x, _ = remove_low_correlation_with_label(x,y, threshold=0.005)\n",
    "    \n",
    "    x = build_model_data(x)\n",
    "    \n",
    "    y = convert_label(y,0)\n",
    "    initial_w = np.zeros((x.shape[1]))\n",
    "    \n",
    "    x_tr, x_val, y_tr, y_val = split_data(x, y, ratio = 0.8, myseed =7) #split the data for validation\n",
    "    \n",
    "    weight,_ = reg_logistic_regression(y_tr, x_tr, lambda_, initial_w, max_iters, gamma)\n",
    "\n",
    "    y_tr_pred = predict(x_tr,weight)\n",
    "\n",
    "    \n",
    "    y_val_pred = predict(x_val,weight)\n",
    "    \n",
    "    print('Training Accuracy : ', np.sum(y_tr_pred==convert_label(y_tr,-1))/y_tr.shape[0])\n",
    "    print('Validation Accuracy : ',np.sum(y_val_pred == convert_label(y_val,-1))/y_val.shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing columns:  [21 29]\n",
      "Removing columns:  [14 15 17 18 23 24 26 27]\n",
      "Training Accuracy :  0.71369\n",
      "Validation Accuracy :  0.71026\n"
     ]
    }
   ],
   "source": [
    "preprocess_and_call_regularized_log_reg(x,y,max_iters=1000,gamma=0.001,lambda_=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gradient_descent(\n",
    "        y, tx, initial_w, batch_size, max_iters, gamma, lambda_):\n",
    "    \"\"\"Batch gradient descent algorithm with variable learning rate\"\"\"\n",
    "\n",
    "    w = initial_w\n",
    "    losses = []\n",
    "    for i in range(max_iters):\n",
    "        if i > 150 and i <= 300:\n",
    "            gamma = 0.05\n",
    "        elif i > 300 and i <= 700 :\n",
    "            gamma = 0.01\n",
    "        elif i > 700 and i <=1000 :\n",
    "            gamma = 0.001\n",
    "        elif i > 1000 and i < 1300 :\n",
    "            gamma = 0.0005\n",
    "        elif i > 1300 and i <= 1600 :\n",
    "            gamma = 0.0001\n",
    "        elif i > 1600 and  i<=1800:\n",
    "            gamma = 0.00005\n",
    "        elif i > 1800:\n",
    "            gamma = 0.00001\n",
    "\n",
    "        for minibatch_y,minibatch_tx in batch_iter(y,tx,batch_size):\n",
    "            \n",
    "            loss, grad =  reg_logistic_gradient(minibatch_y, minibatch_tx, lambda_,initial_w)\n",
    "            w = w - gamma * grad\n",
    "            losses.append(loss)\n",
    "            \n",
    "        avg_loss = np.mean(losses)\n",
    "        \n",
    "    return w,losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_GD_NLL_Loss(x,y,batch_size,max_iters=1000,gamma=0.001,lambda_=0.005):\n",
    "\n",
    "    x,_ = remove_outliers(x)\n",
    "\n",
    "    x, mean_x, std_x = normalize(x)\n",
    "    \n",
    "    x, _ = remove_high_correlation(x, threshold=0.9, visualisation=False)\n",
    "    x, _ = remove_low_correlation_with_label(x,y, threshold=0.005)\n",
    "    \n",
    "    x = build_poly(x,2)\n",
    "    \n",
    "    y = convert_label(y,0)\n",
    "    initial_w = np.zeros((x.shape[1]))\n",
    "    \n",
    "    x_tr, x_val, y_tr, y_val = split_data(x, y, ratio = 0.8, myseed =7) #split the data for validation\n",
    "    \n",
    "    weight,_ = batch_gradient_descent(y_tr, x_tr, initial_w,batch_size, max_iters, gamma,lambda_)\n",
    "\n",
    "    y_tr_pred = predict(x_tr,weight)\n",
    "\n",
    "    \n",
    "    y_val_pred = predict(x_val,weight)\n",
    "    \n",
    "    print('Training Accuracy : ', np.sum(y_tr_pred==convert_label(y_tr,-1))/y_tr.shape[0])\n",
    "    print('Validation Accuracy : ',np.sum(y_val_pred == convert_label(y_val,-1))/y_val.shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing columns:  [21 29]\n",
      "Removing columns:  [14 15 17 18 23 24 26 27]\n",
      "Training Accuracy :  0.69437\n",
      "Validation Accuracy :  0.69058\n"
     ]
    }
   ],
   "source": [
    "batch_GD_NLL_Loss(x,y,256,max_iters=2000,gamma=0.1,lambda_= 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_call_least_squares(x,y):\n",
    "\n",
    "    x,_ = remove_outliers(x)\n",
    "    x, mean_x, std_x = normalize(x)\n",
    "    \n",
    "    x = build_model_data(x)\n",
    "    \n",
    "    initial_w = np.zeros((x.shape[1]))\n",
    "    \n",
    "    x_tr, x_val, y_tr, y_val = split_data(x, y, ratio = 0.8, myseed =7) #split the data for validation\n",
    "    \n",
    "    weight,_ = least_squares(y_tr, x_tr)\n",
    "\n",
    "    y_tr_pred = predict(x_tr,weight)\n",
    "\n",
    "    \n",
    "    y_val_pred = predict(x_val,weight)\n",
    "    \n",
    "    print('Training Accuracy : ', np.sum(y_tr_pred==y_tr)/y_tr.shape[0])\n",
    "    print('Validation Accuracy : ',np.sum(y_val_pred == y_val)/y_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy :  0.74526\n",
      "Validation Accuracy :  0.74006\n"
     ]
    }
   ],
   "source": [
    "preprocess_and_call_least_squares(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_call_least_squares_GD(x,y,max_iters=1000,gamma=0.001):\n",
    "\n",
    "    x,_ = remove_outliers(x)\n",
    "    x, mean_x, std_x = normalize(x)\n",
    "    \n",
    "    x = build_model_data(x)\n",
    "    \n",
    "    initial_w = np.zeros((x.shape[1]))\n",
    "    \n",
    "    x_tr, x_val, y_tr, y_val = split_data(x, y, ratio = 0.8, myseed =7) #split the data for validation\n",
    "    \n",
    "    weight,_ = least_squares_GD(y_tr, x_tr, initial_w, max_iters, gamma)\n",
    "\n",
    "    y_tr_pred = predict(x_tr,weight)\n",
    "\n",
    "    \n",
    "    y_val_pred = predict(x_val,weight)\n",
    "    \n",
    "    print('Training Accuracy : ', np.sum(y_tr_pred==y_tr)/y_tr.shape[0])\n",
    "    print('Validation Accuracy : ',np.sum(y_val_pred == y_val)/y_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy :  0.72622\n",
      "Validation Accuracy :  0.72128\n"
     ]
    }
   ],
   "source": [
    "preprocess_and_call_least_squares_GD(x,y,max_iters=1000,gamma=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_call_least_squares_SGD(x,y,max_iters=1000,gamma=0.001):\n",
    "\n",
    "    x,_ = remove_outliers(x)\n",
    "    x, mean_x, std_x = normalize(x)\n",
    "    \n",
    "    x = build_model_data(x)\n",
    "    \n",
    "    initial_w = np.zeros((x.shape[1]))\n",
    "    \n",
    "    x_tr, x_val, y_tr, y_val = split_data(x, y, ratio = 0.8, myseed =7) #split the data for validation\n",
    "    \n",
    "    weight,_ = least_squares_GD(y_tr, x_tr, initial_w, max_iters, gamma)\n",
    "\n",
    "    y_tr_pred = predict(x_tr,weight)\n",
    "\n",
    "    \n",
    "    y_val_pred = predict(x_val,weight)\n",
    "    \n",
    "    print('Training Accuracy : ', np.sum(y_tr_pred==y_tr)/y_tr.shape[0])\n",
    "    print('Validation Accuracy : ',np.sum(y_val_pred == y_val)/y_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy :  0.72622\n",
      "Validation Accuracy :  0.72128\n"
     ]
    }
   ],
   "source": [
    "preprocess_and_call_least_squares_SGD(x,y,max_iters=1000,gamma=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
